{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:33:31.512531Z",
     "start_time": "2024-07-23T18:33:31.508532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Imports ###\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "from HumanimalClassifier import HumanimalClassifier\n",
    "import config\n",
    "import importlib\n",
    "import pickle\n",
    "from UtilFunctions import extract_landmarks_holistic,extract_landmarks_hand_pose,process_landmarks,predict_landmark_class\n",
    "\n",
    "import os"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:33:42.837588Z",
     "start_time": "2024-07-23T18:33:42.831821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Configs ###\n",
    "Webcam = 1\n",
    "\n",
    "# Change Configs below in config.py\n",
    "### Load Configs ###\n",
    "importlib.reload(config)\n",
    "LandModelType = config.LandModelType\n",
    "\n",
    "Labels = config.Labels\n",
    "label_map = config.GetLabelMap()\n",
    "inv_label_map = config.GetInversLableMap()\n",
    "\n",
    "InFeatures = config.GetInFetures()\n",
    "OutClasses = len(Labels)\n",
    "\n",
    "## Print relevant Config ##\n",
    "print(\"Out Classes: \" + str(OutClasses))\n",
    "print(\"In Features: \" + str(InFeatures))"
   ],
   "id": "8bb8d865db259a47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Classes: 33\n",
      "In Features: 225\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:00:03.958039Z",
     "start_time": "2024-07-23T18:54:35.805125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mp_hands = None\n",
    "mp_pose = None\n",
    "mp_holistic = None\n",
    "\n",
    "# First, initialize a model\n",
    "model = HumanimalClassifier(InFeatures, hiddenlayer=config.Hiddenlayer, num_classes=OutClasses)\n",
    "\n",
    "# Load the weights from the saved model file\n",
    "if config.LandModelType == config.LandModelType.Holistic:\n",
    "    ModelFilename = './Data/Model_classifier_holistic.pth'\n",
    "    mp_holistic = mp.solutions.holistic.Holistic()\n",
    "    print(\"Use Holistic Landmarks\")\n",
    "else:\n",
    "    ModelFilename = './Data/Model_classifier'\n",
    "    if config.LandModelType == config.LandModelType.HandAndPose or config.LandModelType == config.LandModelType.HandOnly:\n",
    "        mp_hands = mp.solutions.hands.Hands(model_complexity=1, min_detection_confidence=0.3,min_tracking_confidence=0.3)\n",
    "        ModelFilename += '_hand'\n",
    "        print(\"Use Hand Landmarks\")\n",
    "    if config.LandModelType == config.LandModelType.HandAndPose or config.LandModelType == config.LandModelType.PoseOnly:\n",
    "        mp_pose = mp.solutions.pose.Pose()\n",
    "        ModelFilename += '_pose'\n",
    "        print(\"Use Pose Landmarks\")\n",
    "    ModelFilename += '.pth'\n",
    "model.load_state_dict(torch.load(ModelFilename))\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "vid = cv.VideoCapture(Webcam)\n",
    "cv.namedWindow('Video', cv.WINDOW_NORMAL)\n",
    "vid.set(cv.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "vid.set(cv.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while (True):\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if LandModelType == LandModelType.Holistic:\n",
    "        landmarks, frame = extract_landmarks_holistic(frame, mp_holistic,config.ValidHandsNeeded)\n",
    "    else:\n",
    "        landmarks, frame = extract_landmarks_hand_pose(frame, mp_hands, mp_pose,config.ValidHandsNeeded, shouldDrawOnImage=True)\n",
    "    if landmarks is None:\n",
    "        cv.putText(frame, \"Keine Geste erkannt\", (50, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "    else:\n",
    "        landmarks = process_landmarks(landmarks)\n",
    "        prediction = predict_landmark_class(landmarks, model)\n",
    "        cv.putText(frame, \"Ohh: \" + str(inv_label_map[prediction]), (50, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "\n",
    "    cv.imshow('Video', frame)\n",
    "\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv.destroyAllWindows()\n",
    "if config.LandModelType == config.LandModelType.Holistic:\n",
    "    mp_holistic.close()\n",
    "if config.LandModelType == config.LandModelType.HandAndPose or config.LandModelType == config.LandModelType.HandOnly:\n",
    "    mp_hands.close()\n",
    "if config.LandModelType == config.LandModelType.HandAndPose or config.LandModelType == config.LandModelType.PoseOnly:\n",
    "    mp_pose.close()"
   ],
   "id": "b1bc933e9d03dbd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Hand Landmarks\n",
      "Use Pose Landmarks\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 40\u001B[0m\n\u001B[0;32m     38\u001B[0m     landmarks, frame \u001B[38;5;241m=\u001B[39m extract_landmarks_holistic(frame, mp_holistic,config\u001B[38;5;241m.\u001B[39mValidHandsNeeded)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 40\u001B[0m     landmarks, frame \u001B[38;5;241m=\u001B[39m extract_landmarks_hand_pose(frame, mp_hands, mp_pose,config\u001B[38;5;241m.\u001B[39mValidHandsNeeded, shouldDrawOnImage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m landmarks \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     42\u001B[0m     cv\u001B[38;5;241m.\u001B[39mputText(frame, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKeine Geste erkannt\u001B[39m\u001B[38;5;124m\"\u001B[39m, (\u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m50\u001B[39m), cv\u001B[38;5;241m.\u001B[39mFONT_HERSHEY_SIMPLEX, \u001B[38;5;241m1\u001B[39m, (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m), \u001B[38;5;241m2\u001B[39m, cv\u001B[38;5;241m.\u001B[39mLINE_AA)\n",
      "File \u001B[1;32mE:\\studium\\SMT\\MainProject\\scientificProject\\UtilFunctions.py:95\u001B[0m, in \u001B[0;36mextract_landmarks_hand_pose\u001B[1;34m(frame, mp_hands, mp_pose, validNeeded, shouldDrawOnImage)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_landmarks_hand_pose\u001B[39m(frame, mp_hands, mp_pose, validNeeded\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, shouldDrawOnImage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 95\u001B[0m     image \u001B[38;5;241m=\u001B[39m cv\u001B[38;5;241m.\u001B[39mcvtColor(frame, cv\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB)\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m(mp_hands):\n\u001B[0;32m     98\u001B[0m         \u001B[38;5;66;03m# Process the image\u001B[39;00m\n\u001B[0;32m     99\u001B[0m         hands_results \u001B[38;5;241m=\u001B[39m mp_hands\u001B[38;5;241m.\u001B[39mprocess(image)\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c08fa1412b01f11c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
