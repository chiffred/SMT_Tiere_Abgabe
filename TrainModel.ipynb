{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T10:13:02.740086Z",
     "start_time": "2024-07-24T10:13:01.119506Z"
    }
   },
   "source": [
    "### Imports ###\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "from HumanimalClassifier import HumanimalClassifier\n",
    "import config\n",
    "import importlib\n",
    "import numpy as np\n",
    "from UtilFunctions import process_landmarks"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T10:13:55.838120Z",
     "start_time": "2024-07-24T10:13:49.643801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Configs ###\n",
    "\n",
    "\n",
    "# Change Configs below in config.py\n",
    "### Load Configs ###\n",
    "importlib.reload(config)\n",
    "LandModelType = config.LandModelType\n",
    "\n",
    "## Stuff with the configs ##\n",
    "# Load Landmarks from file ##\n",
    "if LandModelType == LandModelType.Holistic:\n",
    "    landmarkFilename = f'./Data/landmarks_holistic_default.pkl'\n",
    "    landmarkFilenameVal = f'./Data/landmarks_holistic_val.pkl'\n",
    "else:\n",
    "    landmarkFilename = './Data/landmarks_'\n",
    "    InFeatures = 0\n",
    "    if LandModelType == LandModelType.HandAndPose or LandModelType == LandModelType.HandOnly:\n",
    "        landmarkFilename += 'hand_'\n",
    "    if LandModelType == LandModelType.HandAndPose or LandModelType == LandModelType.PoseOnly:\n",
    "        landmarkFilename += 'pose_'\n",
    "    landmarkFilenameVal = landmarkFilename + 'val.pkl'\n",
    "    landmarkFilename += 'default.pkl'\n",
    "\n",
    "with open(landmarkFilename, 'rb') as f:\n",
    "    landmarks_dataset = pickle.load(f)\n",
    "with open(landmarkFilenameVal, 'rb') as f:\n",
    "    landmarks_dataset_val = pickle.load(f)\n",
    "\n",
    "Labels = config.Labels\n",
    "label_map = config.GetLabelMap()\n",
    "inv_label_map = config.GetInversLableMap()\n",
    "\n",
    "InFeatures = config.GetInFetures()\n",
    "OutClasses = len(Labels)\n",
    "\n",
    "## Print relevant Config ##\n",
    "print(LandModelType)\n",
    "print(\"Out Classes: \" + str(OutClasses))\n",
    "print(\"In Features: \" + str(InFeatures))\n",
    "print(\"Hidden layer: \" + str(config.Hiddenlayer))\n",
    "print(\"Batch Size: \" + str(config.batch_size))\n",
    "print(\"Learning Rate: \" + str(config.LearningRate))\n",
    "print(\"Num epochs: \" + str(config.num_epochs))"
   ],
   "id": "bbf42a6e306e4610",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LandmarkModelEnum.HandAndPose\n",
      "Out Classes: 33\n",
      "In Features: 225\n",
      "Hidden layer: 450\n",
      "Batch Size: 16\n",
      "Learning Rate: 0.00025\n",
      "Num epochs: 40\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T10:21:25.639905Z",
     "start_time": "2024-07-24T10:13:59.580355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Train Data\n",
    "landmarks_list = [item[0] for item in landmarks_dataset]\n",
    "labels_list = [item[1] for item in landmarks_dataset]\n",
    "\n",
    "landmarks_tensor = torch.stack(landmarks_list)\n",
    "labels_list = [label_map[item[1]] for item in landmarks_dataset]\n",
    "labels_tensor = torch.tensor(labels_list)\n",
    "\n",
    "tensor_dataset = TensorDataset(landmarks_tensor, labels_tensor)\n",
    "data_loader = DataLoader(tensor_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "## Validation Data\n",
    "landmarks_list_val = [item[0] for item in landmarks_dataset_val]\n",
    "labels_list_val = [item[1] for item in landmarks_dataset_val]\n",
    "\n",
    "landmarks_tensor_val = torch.stack(landmarks_list_val)\n",
    "labels_list_val = [label_map[item[1]] for item in landmarks_dataset_val]\n",
    "labels_tensor_val = torch.tensor(labels_list_val)\n",
    "\n",
    "tensor_dataset_val = TensorDataset(landmarks_tensor_val, labels_tensor_val)\n",
    "data_loader_val = DataLoader(tensor_dataset_val, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "# Setup the model, criterion, and optimizer\n",
    "model = HumanimalClassifier(in_feat=InFeatures, hiddenlayer=config.Hiddenlayer, num_classes=OutClasses)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LearningRate)\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(config.num_epochs):\n",
    "    loss_total = 0\n",
    "    correct_total = 0\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()  # change it back to float\n",
    "        labels_one_hot = F.one_hot(labels.to(torch.int64), num_classes=OutClasses)  # use labels as int64 for one-hot function\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels_one_hot.float())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update total loss\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        correct_total += correct\n",
    "\n",
    "    # calculate average loss and accuracy\n",
    "    avg_loss = loss_total / len(data_loader)\n",
    "    avg_acc = correct_total / len(data_loader.dataset)\n",
    "    print(f'Epoch [{epoch + 1}/{config.num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.2f}')\n",
    "            \n",
    "    #test after each epoch\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader_val:\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        valid_accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{config.num_epochs}], Validation Accuracy: {valid_accuracy:.2f}')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "if LandModelType == LandModelType.Holistic:\n",
    "    ModelFilename = f'./Data/Model_classifier_holistic.pth'\n",
    "else:\n",
    "    ModelFilename = './Data/Model_classifier'\n",
    "    if LandModelType == LandModelType.HandAndPose or LandModelType == LandModelType.HandOnly:\n",
    "        ModelFilename += '_hand'\n",
    "        InFeatures += config.InFeaturesHand\n",
    "    if LandModelType == LandModelType.HandAndPose or LandModelType == LandModelType.PoseOnly:\n",
    "        ModelFilename += '_pose'\n",
    "        InFeatures += config.InFeaturesPose\n",
    "    ModelFilename += '.pth'\n",
    "    \n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}: {param.shape}')\n",
    "torch.save(model.state_dict(), ModelFilename)\n",
    "\n"
   ],
   "id": "f7f0b594a77595c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 0.0168, Accuracy: 0.68\n",
      "Epoch [1/40], Validation Accuracy: 0.81\n",
      "Epoch [2/40], Loss: 0.0089, Accuracy: 0.88\n",
      "Epoch [2/40], Validation Accuracy: 0.84\n",
      "Epoch [3/40], Loss: 0.0063, Accuracy: 0.93\n",
      "Epoch [3/40], Validation Accuracy: 0.86\n",
      "Epoch [4/40], Loss: 0.0051, Accuracy: 0.94\n",
      "Epoch [4/40], Validation Accuracy: 0.89\n",
      "Epoch [5/40], Loss: 0.0044, Accuracy: 0.95\n",
      "Epoch [5/40], Validation Accuracy: 0.90\n",
      "Epoch [6/40], Loss: 0.0038, Accuracy: 0.96\n",
      "Epoch [6/40], Validation Accuracy: 0.88\n",
      "Epoch [7/40], Loss: 0.0035, Accuracy: 0.97\n",
      "Epoch [7/40], Validation Accuracy: 0.89\n",
      "Epoch [8/40], Loss: 0.0032, Accuracy: 0.97\n",
      "Epoch [8/40], Validation Accuracy: 0.90\n",
      "Epoch [9/40], Loss: 0.0029, Accuracy: 0.97\n",
      "Epoch [9/40], Validation Accuracy: 0.89\n",
      "Epoch [10/40], Loss: 0.0027, Accuracy: 0.97\n",
      "Epoch [10/40], Validation Accuracy: 0.91\n",
      "Epoch [11/40], Loss: 0.0026, Accuracy: 0.98\n",
      "Epoch [11/40], Validation Accuracy: 0.90\n",
      "Epoch [12/40], Loss: 0.0024, Accuracy: 0.98\n",
      "Epoch [12/40], Validation Accuracy: 0.90\n",
      "Epoch [13/40], Loss: 0.0023, Accuracy: 0.98\n",
      "Epoch [13/40], Validation Accuracy: 0.91\n",
      "Epoch [14/40], Loss: 0.0022, Accuracy: 0.98\n",
      "Epoch [14/40], Validation Accuracy: 0.89\n",
      "Epoch [15/40], Loss: 0.0021, Accuracy: 0.98\n",
      "Epoch [15/40], Validation Accuracy: 0.92\n",
      "Epoch [16/40], Loss: 0.0020, Accuracy: 0.98\n",
      "Epoch [16/40], Validation Accuracy: 0.90\n",
      "Epoch [17/40], Loss: 0.0019, Accuracy: 0.98\n",
      "Epoch [17/40], Validation Accuracy: 0.92\n",
      "Epoch [18/40], Loss: 0.0018, Accuracy: 0.98\n",
      "Epoch [18/40], Validation Accuracy: 0.92\n",
      "Epoch [19/40], Loss: 0.0018, Accuracy: 0.98\n",
      "Epoch [19/40], Validation Accuracy: 0.92\n",
      "Epoch [20/40], Loss: 0.0017, Accuracy: 0.98\n",
      "Epoch [20/40], Validation Accuracy: 0.91\n",
      "Epoch [21/40], Loss: 0.0017, Accuracy: 0.98\n",
      "Epoch [21/40], Validation Accuracy: 0.92\n",
      "Epoch [22/40], Loss: 0.0016, Accuracy: 0.98\n",
      "Epoch [22/40], Validation Accuracy: 0.93\n",
      "Epoch [23/40], Loss: 0.0016, Accuracy: 0.98\n",
      "Epoch [23/40], Validation Accuracy: 0.92\n",
      "Epoch [24/40], Loss: 0.0015, Accuracy: 0.98\n",
      "Epoch [24/40], Validation Accuracy: 0.93\n",
      "Epoch [25/40], Loss: 0.0015, Accuracy: 0.98\n",
      "Epoch [25/40], Validation Accuracy: 0.91\n",
      "Epoch [26/40], Loss: 0.0014, Accuracy: 0.98\n",
      "Epoch [26/40], Validation Accuracy: 0.91\n",
      "Epoch [27/40], Loss: 0.0014, Accuracy: 0.99\n",
      "Epoch [27/40], Validation Accuracy: 0.92\n",
      "Epoch [28/40], Loss: 0.0014, Accuracy: 0.99\n",
      "Epoch [28/40], Validation Accuracy: 0.89\n",
      "Epoch [29/40], Loss: 0.0013, Accuracy: 0.99\n",
      "Epoch [29/40], Validation Accuracy: 0.91\n",
      "Epoch [30/40], Loss: 0.0013, Accuracy: 0.99\n",
      "Epoch [30/40], Validation Accuracy: 0.94\n",
      "Epoch [31/40], Loss: 0.0013, Accuracy: 0.99\n",
      "Epoch [31/40], Validation Accuracy: 0.92\n",
      "Epoch [32/40], Loss: 0.0012, Accuracy: 0.99\n",
      "Epoch [32/40], Validation Accuracy: 0.92\n",
      "Epoch [33/40], Loss: 0.0012, Accuracy: 0.99\n",
      "Epoch [33/40], Validation Accuracy: 0.93\n",
      "Epoch [34/40], Loss: 0.0012, Accuracy: 0.99\n",
      "Epoch [34/40], Validation Accuracy: 0.92\n",
      "Epoch [35/40], Loss: 0.0012, Accuracy: 0.99\n",
      "Epoch [35/40], Validation Accuracy: 0.93\n",
      "Epoch [36/40], Loss: 0.0011, Accuracy: 0.99\n",
      "Epoch [36/40], Validation Accuracy: 0.91\n",
      "Epoch [37/40], Loss: 0.0011, Accuracy: 0.99\n",
      "Epoch [37/40], Validation Accuracy: 0.92\n",
      "Epoch [38/40], Loss: 0.0011, Accuracy: 0.99\n",
      "Epoch [38/40], Validation Accuracy: 0.91\n",
      "Epoch [39/40], Loss: 0.0010, Accuracy: 0.99\n",
      "Epoch [39/40], Validation Accuracy: 0.92\n",
      "Epoch [40/40], Loss: 0.0010, Accuracy: 0.99\n",
      "Epoch [40/40], Validation Accuracy: 0.92\n",
      "Finished Training\n",
      "layer1.weight: torch.Size([450, 225])\n",
      "layer1.bias: torch.Size([450])\n",
      "layer2.weight: torch.Size([225, 450])\n",
      "layer2.bias: torch.Size([225])\n",
      "layer3.weight: torch.Size([33, 225])\n",
      "layer3.bias: torch.Size([33])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:00:57.170015Z",
     "start_time": "2024-07-19T13:00:57.127157Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2e154aea967b3615",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:00:57.197321Z",
     "start_time": "2024-07-19T13:00:57.192491Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "17e38c5499c2cb8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T13:00:57.206559Z",
     "start_time": "2024-07-19T13:00:57.201333Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ce8f763b3391e257",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
